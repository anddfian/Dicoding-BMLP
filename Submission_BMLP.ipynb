{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vNDaXFRmUEY0",
        "outputId": "60b44b25-8c1d-4532-d5fa-2c1289f8eb99"
      },
      "source": [
        "pip install split_folders"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting split_folders\n",
            "  Downloading split_folders-0.4.3-py3-none-any.whl (7.4 kB)\n",
            "Installing collected packages: split-folders\n",
            "Successfully installed split-folders-0.4.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VfEoIz6MlDQl"
      },
      "source": [
        "import tensorflow as tf"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kJCAjuLelGwd",
        "outputId": "62e39d33-ce2d-407c-925a-70d21605bcfc"
      },
      "source": [
        "!wget --no-check-certificate \\\n",
        "  https://github.com/anddfian/kb/blob/master/eyes-rtte.zip?raw=true \\\n",
        "  -O /tmp/rockpaperscissors.zip"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2021-11-28 08:55:33--  https://github.com/dicodingacademy/assets/releases/download/release/rockpaperscissors.zip\n",
            "Resolving github.com (github.com)... 140.82.114.4\n",
            "Connecting to github.com (github.com)|140.82.114.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://github-releases.githubusercontent.com/391417272/7eb836f2-695b-4a46-9c78-b65867166957?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20211128%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20211128T085533Z&X-Amz-Expires=300&X-Amz-Signature=f72a1b20a069c696f020e8473dcd18149b406636d73603e92e78a5fd2213f9ca&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=391417272&response-content-disposition=attachment%3B%20filename%3Drockpaperscissors.zip&response-content-type=application%2Foctet-stream [following]\n",
            "--2021-11-28 08:55:33--  https://github-releases.githubusercontent.com/391417272/7eb836f2-695b-4a46-9c78-b65867166957?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20211128%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20211128T085533Z&X-Amz-Expires=300&X-Amz-Signature=f72a1b20a069c696f020e8473dcd18149b406636d73603e92e78a5fd2213f9ca&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=391417272&response-content-disposition=attachment%3B%20filename%3Drockpaperscissors.zip&response-content-type=application%2Foctet-stream\n",
            "Resolving github-releases.githubusercontent.com (github-releases.githubusercontent.com)... 185.199.108.154, 185.199.109.154, 185.199.110.154, ...\n",
            "Connecting to github-releases.githubusercontent.com (github-releases.githubusercontent.com)|185.199.108.154|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 322873683 (308M) [application/octet-stream]\n",
            "Saving to: ‘/tmp/rockpaperscissors.zip’\n",
            "\n",
            "/tmp/rockpapersciss 100%[===================>] 307.92M  44.9MB/s    in 6.5s    \n",
            "\n",
            "2021-11-28 08:55:40 (47.5 MB/s) - ‘/tmp/rockpaperscissors.zip’ saved [322873683/322873683]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kuNGSfVGlIEz"
      },
      "source": [
        "# melakukan ekstraksi pada file zip\n",
        "import zipfile\n",
        "local_zip = '/tmp/rockpaperscissors.zip'\n",
        "zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
        "zip_ref.extractall('/tmp')\n",
        "zip_ref.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wPKJt8GylJXd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "01e104d7-482e-4127-9487-b90760e8b5cc"
      },
      "source": [
        "import os\n",
        "os.listdir('/tmp/rockpaperscissors')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['README_rpc-cv-images.txt', 'rps-cv-images', 'rock', 'scissors', 'paper']"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rnn0nNsb2OMb",
        "outputId": "735ac319-6fe6-405a-9617-1aabd1c95385"
      },
      "source": [
        "import splitfolders\n",
        "base_dir = '/tmp/rockpaperscissors/rps-cv-images'\n",
        "splitfolders.ratio(base_dir, output = '/tmp/rockpaperscissors', seed = 1337, ratio = (.4, .6))\n",
        "\n",
        "train_dir = os.path.join('/tmp/rockpaperscissors', 'train')\n",
        "validation_dir = os.path.join('/tmp/rockpaperscissors', 'val')\n",
        "\n",
        "rock_dir = os.path.join(base_dir, 'rock')\n",
        "paper_dir = os.path.join(base_dir, 'paper')\n",
        "scissors_dir = os.path.join(base_dir, 'scissors')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Copying files: 2188 files [00:00, 4036.59 files/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pURKfGVV3wOz"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "# membagi direktori rock menjadi data train dan validasi data\n",
        "train_rock_dir, validation_rock_dir = train_test_split(os.listdir(rock_dir), test_size = 0.4, train_size = 0.6)\n",
        "\n",
        "# membagi direktori paper menjadi data train dan validasi data\n",
        "train_paper_dir, validation_paper_dir = train_test_split(os.listdir(paper_dir), test_size = 0.4, train_size = 0.6)\n",
        "\n",
        "# membagi direktori scissors menjadi data train dan validasi data\n",
        "train_scissors_dir, validation_scissors_dir = train_test_split(os.listdir(scissors_dir), test_size = 0.4, train_size = 0.6)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iUaUjNkJlMo0"
      },
      "source": [
        "# membuat direktori rock pada direktori data training\n",
        "train_rock_dir = os.path.join(train_dir, 'rock')\n",
        "\n",
        "# membuat direktori paper pada direktori data training\n",
        "train_paper_dir = os.path.join(train_dir, 'paper')\n",
        "\n",
        "# membuat direktori scissors pada direktori data training\n",
        "train_scissors_dir = os.path.join(train_dir, 'scissors')\n",
        "\n",
        "# membuat direktori rock pada direktori data validation\n",
        "validation_rock = os.path.join(validation_dir, 'rock')\n",
        "\n",
        "# membuat direktori paper pada direktori data validation\n",
        "validation_paper = os.path.join(validation_dir, 'paper') \n",
        "\n",
        "# membuat direktori scissors pada direktori data validation\n",
        "validation_scissors = os.path.join(validation_dir, 'scissors')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wPav3zIZlOL0"
      },
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "train_datagen = ImageDataGenerator(\n",
        "                    rescale=1./255,\n",
        "                    rotation_range=20,\n",
        "                    horizontal_flip=True,\n",
        "                    shear_range = 0.2,\n",
        "                    fill_mode = 'nearest')\n",
        "\n",
        "test_datagen = ImageDataGenerator(\n",
        "                    rescale=1./255,\n",
        "                    rotation_range=20,\n",
        "                    horizontal_flip=True,\n",
        "                    shear_range = 0.2,\n",
        "                    fill_mode = 'nearest')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GrH6FJEvlPnj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0babc82e-827e-4d40-893a-37121e00bfe2"
      },
      "source": [
        "train_generator = train_datagen.flow_from_directory(\n",
        "        train_dir,\n",
        "        target_size=(150, 150),\n",
        "        batch_size=32,\n",
        "        class_mode='categorical')\n",
        "\n",
        "validation_generator = test_datagen.flow_from_directory(\n",
        "        validation_dir,\n",
        "        target_size=(150, 150),\n",
        "        batch_size=32,\n",
        "        class_mode='categorical')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 874 images belonging to 3 classes.\n",
            "Found 1314 images belonging to 3 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-kub0Iw3lQQD"
      },
      "source": [
        "model = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(150, 150, 3)),\n",
        "    tf.keras.layers.MaxPooling2D(2, 2),\n",
        "    tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(2, 2),\n",
        "    tf.keras.layers.Conv2D(128, (3, 3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(2, 2),\n",
        "    tf.keras.layers.Conv2D(128, (3, 3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(2, 2),\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(512, activation='relu'),\n",
        "    tf.keras.layers.Dense(3, activation='softmax')\n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FpvCTUXrlSwD"
      },
      "source": [
        "# compile model dengan 'adam' optimizer loss function 'categorical_crossentropy'\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=tf.optimizers.Adam(),\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_lNZnv1olT_F",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "edea5e3c-1e6c-442a-c16b-6059b7b49704"
      },
      "source": [
        "# latih model dengan model.fit \n",
        "model.fit(\n",
        "      train_generator,\n",
        "      steps_per_epoch=25,\n",
        "      epochs=20,\n",
        "      validation_data=validation_generator,\n",
        "      validation_steps=5\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "25/25 [==============================] - 44s 2s/step - loss: 1.0779 - accuracy: 0.3946 - val_loss: 0.9024 - val_accuracy: 0.6625\n",
            "Epoch 2/20\n",
            "25/25 [==============================] - 42s 2s/step - loss: 0.6563 - accuracy: 0.7416 - val_loss: 0.6173 - val_accuracy: 0.7188\n",
            "Epoch 3/20\n",
            "25/25 [==============================] - 42s 2s/step - loss: 0.3723 - accuracy: 0.8779 - val_loss: 0.2268 - val_accuracy: 0.9438\n",
            "Epoch 4/20\n",
            "25/25 [==============================] - 42s 2s/step - loss: 0.2693 - accuracy: 0.9203 - val_loss: 0.2796 - val_accuracy: 0.8938\n",
            "Epoch 5/20\n",
            "25/25 [==============================] - 42s 2s/step - loss: 0.2160 - accuracy: 0.9254 - val_loss: 0.2596 - val_accuracy: 0.9000\n",
            "Epoch 6/20\n",
            "25/25 [==============================] - 43s 2s/step - loss: 0.1532 - accuracy: 0.9475 - val_loss: 0.3630 - val_accuracy: 0.8938\n",
            "Epoch 7/20\n",
            "25/25 [==============================] - 42s 2s/step - loss: 0.2076 - accuracy: 0.9383 - val_loss: 0.2431 - val_accuracy: 0.9125\n",
            "Epoch 8/20\n",
            "25/25 [==============================] - 44s 2s/step - loss: 0.1726 - accuracy: 0.9447 - val_loss: 0.2172 - val_accuracy: 0.9250\n",
            "Epoch 9/20\n",
            "25/25 [==============================] - 42s 2s/step - loss: 0.1277 - accuracy: 0.9640 - val_loss: 0.2880 - val_accuracy: 0.9375\n",
            "Epoch 10/20\n",
            "25/25 [==============================] - 42s 2s/step - loss: 0.0877 - accuracy: 0.9717 - val_loss: 0.1438 - val_accuracy: 0.9438\n",
            "Epoch 11/20\n",
            "25/25 [==============================] - 42s 2s/step - loss: 0.1019 - accuracy: 0.9730 - val_loss: 0.1301 - val_accuracy: 0.9563\n",
            "Epoch 12/20\n",
            "19/25 [=====================>........] - ETA: 9s - loss: 0.0931 - accuracy: 0.9638 "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u9rzSCcKlUjk"
      },
      "source": [
        "import numpy as np\n",
        "from google.colab import files\n",
        "from keras.preprocessing import image\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "%matplotlib inline\n",
        "\n",
        "uploaded = files.upload()\n",
        "\n",
        "for fn in uploaded.keys():\n",
        "\n",
        "  # predicting images\n",
        "  path = fn\n",
        "  img = image.load_img(path, target_size=(150,150))\n",
        "  imgplot = plt.imshow(img)\n",
        "  x = image.img_to_array(img)\n",
        "  x = np.expand_dims(x, axis=0)\n",
        " \n",
        "  images = np.vstack([x])\n",
        "  classes = model.predict(images, batch_size=10)\n",
        "  \n",
        "  print(fn)\n",
        "  if classes[0][0] == 1:\n",
        "    print('Paper')\n",
        "  elif classes[0][1] == 1:\n",
        "    print('Rock')\n",
        "  elif classes[0][2] == 1:\n",
        "    print('Scissor')\n",
        "  else:\n",
        "    print('Unknown')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p_LpCQX1Oa33"
      },
      "source": [
        "Nama  : Andi Alfian Bahtiar |\n",
        "Email : andd.fian@gmail.com"
      ]
    }
  ]
}